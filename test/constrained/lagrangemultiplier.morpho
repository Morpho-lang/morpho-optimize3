// Test PenaltyAdapter and PenaltyController 

import optimize3

var _OptUnConsErr = Error("OpUncons", "Problem appears to be unconstrained.")

class LagrangeMultiplierAdapter is OptimizationAdapter {
  init(adapter) {
    self.adapter = adapter
    self.nconstraints = self.constraintvector().count() 
    self.lambda = Matrix(self.nconstraints)
  }

  set(x) { // Get parameters, stripping off lagrange multipliers
    var n = x.count()
    var nvars = n - self.nconstraints
    self.adapter.set(x[0...nvars,0])
    self.lambda = x[nvars...n,0] // Store lagrange multipliers on this adapter
  }

  get() { // Get parameters, joining real parameters with lagrange multipliers
    var x = self.adapter.get()
    return Matrix([[x], [self.lambda]]) 
  }

  lagrangemultipliers() {
    return self.lambda 
  }

  _checkineq(c) {
    var nc = self.adapter.countconstraints()
    for (k in nc[0]...nc[0]+nc[1]) {
      if (c[k]>0) c[k]=0
    }
  }

  constraintvector() {
    var v = self.adapter.constraintvalue()

    if (v) {
      v = Matrix(v)
      self._checkineq(v)
    } else _OptUnConsErr.warning() 

    return v 
  }

  value() { // Lagrangian = f + lambda_i c_i
    var f = self.adapter.value() 
    var c = self.constraintvector()

    return f + self.lambda.inner(c)  
  }

  gradient() { // Gradient of Lagrangian is [ df + lambda_i dc_i , c_i] 
    var grad = self.adapter.gradient()

    var c = self.constraintvector()
    var cgrad = self.adapter.constraintgradient()

    for (cg,k in cgrad) grad += self.lambda[k]*cg

    return Matrix([[grad],[c]]) 
  } 

  hessian() { // Hessian of Lagrangian is the kkt matrix 
    var h = self.adapter.hessian()    

    var chess = self.adapter.constrainthessian() 
    for (ch,k in chess) h += self.lambda[k]*ch

    var cg = self.adapter.constraintgradient()
    var C = Matrix([cg])

    return Matrix([[h, C],[C.transpose(), 0]])
  }
}

fn func(x, y, z) {
  return (x+2)^2 + 0.5*(y-2)^4 + 2*(z-2)^2
}

fn g(x, y, z) {
  return x + y - 1
}

fn h(x, y, z) {
  return 1 - (x^2 + y^2 + z^2)
}

var start = Matrix([1,1,1])

var adapt = FunctionAdapter(func, start=start, constraints = [g], inequalitycount=0)

var ladapt = LagrangeMultiplierAdapter(adapt) 

print ladapt.value() 

var control = NewtonController(ladapt)

control.optimize(10)

print ladapt.get()

var start = Matrix([1,1,1])

var adapt = FunctionAdapter(func, start=start, constraints = [g], inequalitycount=0)

var ladapt = LagrangeMultiplierAdapter(adapt) 

//var padapt = PenaltyAdapter(adapt, penalty=100)
var lscontroller = GradientDescentController(adapt, stepsize=1)

var control = BFGSController(ladapt, linesearch=lscontroller)

control.optimize(20)

print control.hasconverged()

print ladapt.get()
