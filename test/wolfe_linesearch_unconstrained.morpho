// Test the LineSearchController on a poorly scaled quadratic

import optimize3

var _OptLnSrchDrn = Error("OptLnSrchDrn", "Linesearch encountered an upward direction.")
var _OptLnSrchStpsz = Error("OptLnSrchStpsz", "Linesearch stepsize has tended to zero.")

class XLineSearchController is GradientDescentController {
  init(adapter, quiet=false, stepsize=0.1, alpha=0.2, beta=0.5) {
    super.init(adapter, quiet=quiet)
    self.maxsteps = 50 // Maximum steps for reducing stepsize
    self.alpha = alpha // } Coefficients 
    self.beta = beta   // }
  }

  expecteddescent() { // Predict expected descent
    self.df = self._gradient.inner(self._direction)

    if (self.df>0) _OptLnSrchDrn.warning()
  }

  accept(t) { // Have we descended sufficiently?
    return self._value < self._ovalue + self.alpha*t*self.df
  }

  stepwith(x0, t) { // Take a step of size t from x0 in the descent direction
    var x = x0 + t*self._direction
    self.adapter.set(x)

    return self.value()
  }

  step() {// Perform a single linesearch
    self.expecteddescent()
    var t=1
    var success=false
    self._ovalue = self._value // Save value for comparison

    var x0 = self.adapter.get() 
    for (_ in 1..self.maxsteps) {
        self.stepwith(x0, t)
        success=self.accept(t)
        if (success) break
        t*=self.beta
    }
    if (!success) _OptLnSrchStpsz.warning()

    self.stepsize=t
  }


}

// Linesearches that satisfy strong Wolfe conditions 
// See Nocedal and Wright Chapter 3, p60
// See also SciPy implementation https://indrag49.github.io/Numerical-Optimization/line-search-descent-methods.html#selection-of-step-length

class WolfeLineSearchController is GradientDescentController {
  init(adapter, quiet=false, stepsize=1, steplimit=2, c1=1e-4, c2=0.9) {
    super.init(adapter, quiet=quiet)
    self.maxsteps = 50 // Maximum steps for reducing stepsize
    self.stepsize = stepsize   // Initial stepsize
    self.steplimit = steplimit // Stepsize limit
    self.c1 = c1 // } Coefficients 
    self.c2 = c2 // }
  }

  expecteddescent() { // Predict expected descent
    self.df = self._gradient.inner(self._direction)

    if (self.df>0) _OptLnSrchDrn.warning()
  }

  stepwith(x0, t) { // Take a step of size t from x0 in the descent direction
    var x = x0 + t*self._direction
    self.adapter.set(x)

    return self.value()
  }

  _interpolate(f0, df, alpha, fa) {
    return - df*alpha^2/(2*(fa-f0-df*alpha))
  }

  _zoom(alphalo0, alphahi0, x0, f0, df) {
    var alphalo = alphalo0, alphahi = alphahi0
    var flo = self.stepwith(x0, alphalo)

    for (_ in 1..10) {
      var alpha = (alphalo+alphahi)/2 // Bisection

      var f = self.stepwith(x0, alpha)

      if (f>f0+self.c1*alpha*df || // Armijo condition
          f >= flo) {
            alphahi = alpha 
      } else {
        self.gradient() 
        var dfalpha = self._gradient.inner(self._direction)

        if (abs(dfalpha) <= self.c2*abs(df)) { // Curvature condition
          self.stepsize = alpha 
          return 
        } else if (dfalpha*(alphahi-alphalo)>=0) {
          alphahi = alphalo 
        }
        alphalo = alpha  
      }
    }
 
    // raise error 
    return 
  }

  step() { // Perform a single linesearch; Alg. 3.5 of N&D
    self.expecteddescent()

    var f0 = self._value 
    var df = self.df 
    var x0 = self.adapter.get() 

    var alpha=self.stepsize
    var oalpha=0
    var of = f0 

    for (_ in 1..10) {
      var f = self.stepwith(x0, alpha)

      if (f>f0+self.c1*alpha*df ||
          f>=of) { // Step is too long if Armijo test fails or the function simply increased
        return self._zoom(oalpha, alpha, x0, f0, df) 
      }

      self.gradient() 
      var dfalpha = self._gradient.inner(self._direction)

      if (abs(dfalpha) <= self.c2*abs(df)) { // Curvature test
        self.stepsize = alpha // Success
        return 
      }

      if (dfalpha>=0) { // Gradient is upward so reduce stepsize
        return self._zoom(alpha, oalpha, x0, f0, df)
      }
      
      of = f 
      oalpha = alpha 

      alpha = self._interpolate(f0, df, alpha, f)
      //alpha = (alpha+self.steplimit)/2
    }
  }
}




fn func(x, y) {
    return (x^2 + y - 11)^2 + (x + y^2 - 7)^2
}

var start = Matrix([-2.5,2.8])

var adapt = FunctionAdapter(func, start=start)


/*
fn func(x, y, z) {
    return (x-0.5)^2 + (y-1)^2 + 0.25*(z-4)^2
}

var start = Matrix([20,3.1,0])

var adapt = FunctionAdapter(func, start=start)

*/

/*
import "quadratic.morpho"

var f = Quadratic([1.3, -0.5, 0.9, 1.2, 5], [1,5,0.1,3,0.1]).func() 

var adapt = FunctionAdapter(f, start=Matrix(5))

*/

var proxy = ProxyAdapter(adapt)
//var control = XLineSearchController(proxy)
var control = WolfeLineSearchController(proxy)

control.optimize(1000)
print adapt.get()

proxy.report()
